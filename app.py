import streamlit as st
import pandas as pd
import plotly.express as px
import pickle
from pathlib import Path
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

st.set_page_config(
    page_title="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω –Ω–∞ –º–∞—à–∏–Ω—ã",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded"
)

MODEL_DIR = Path(__file__).resolve().parent.parent / "models"
MEDIAN_PATH = MODEL_DIR / "medians.pkl"
SCALER_PATH = MODEL_DIR / "scaler.pkl"
MODEL_PATH = MODEL_DIR / "churn_model.pkl"
FEATURE_NAMES_PATH = MODEL_DIR / "feature_names.pkl"


@st.cache_resource
def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ pickle"""

    with open(MODEL_PATH, 'rb') as f:
        model = pickle.load(f)
    with open(SCALER_PATH, 'rb') as f:
        scaler = pickle.load(f)
    with open(MEDIAN_PATH, 'rb') as f:
        medians = pickle.load(f)
    with open(FEATURE_NAMES_PATH, 'rb') as f:
        feature_names = pickle.load(f)
    return model, scaler, medians, feature_names

# --- –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---
st.title("üöó –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω –Ω–∞ –º–∞—à–∏–Ω—ã")


model, scaler, medians, feature_names = load_model()

#–ù–∞—Ä–∏—Å—É–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ –ø–æ train
#–ó–∞–≥—Ä—É–∑–∏–º –¥–∞—Ç–∞—Å–µ—Ç train
@st.cache_data
def load_train():
    url = 'https://raw.githubusercontent.com/Murcha1990/MLDS_ML_2022/main/Hometasks/HT1/cars_train.csv'
    df_train = pd.read_csv(url)
    return df_train

@st.cache_data
def obrabotka_train():
    url = 'https://raw.githubusercontent.com/Murcha1990/MLDS_ML_2022/main/Hometasks/HT1/cars_train.csv'
    df_train_new = pd.read_csv(url)
   #–ù—É–∂–Ω–æ —É–±—Ä–∞—Ç—å –≤—Å–µ –ª–∏—à–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
    processed_train = df_train_new.copy()
    
    #–£–±–∏—Ä–∞–µ–º ' kmpl' –∏–∑ mileage
    if 'mileage' in processed_train.columns:
        if processed_train['mileage'].dtype == 'object':
            processed_train['mileage'] = processed_train['mileage'].str.replace(' kmpl', '', regex=False)
        processed_train['mileage'] = pd.to_numeric(processed_train['mileage'], errors='coerce')
    
    #–£–±–∏—Ä–∞–µ–º ' CC' –∏–∑ engine
    if 'engine' in processed_train.columns:
        if processed_train['engine'].dtype == 'object':
            processed_train['engine'] = processed_train['engine'].str.replace(' CC', '', regex=False)
        processed_train['engine'] = pd.to_numeric(processed_train['engine'], errors='coerce')
    
    #–£–±–∏—Ä–∞–µ–º ' bhp' –¥–ª—è max_power
    if 'max_power' in processed_train.columns:
        if processed_train['max_power'].dtype == 'object':
            processed_train['max_power'] = processed_train['max_power'].str.replace(' bhp', '', regex=False)
        processed_train['max_power'] = pd.to_numeric(processed_train['max_power'], errors='coerce')
    
    return processed_train

st.subheader("üìâ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ train, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ–±—É—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å")
#–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∞—Ö –¥–∞—Ç–∞—Å–µ—Ç

#–ö–∞—Ä—Ç–æ—á–∫–∏ —Å –º–µ–¥–∏–∞–Ω–∞–º–∏ –ø–æ –∫—á–∏—Å–ª–æ–≤—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º
def median_metrics():
    df_train = obrabotka_train()
    
    col1, col2, col3, col4, col5, col6 = st.columns(6)

    with col1:
        median_year = int(df_train['year'].median())
        st.metric(
            label="–ú–µ–¥–∏–∞–Ω–∞ –≥–æ–¥–∞ –≤—ã–ø—É—Å–∫–∞",
            value=f"{median_year}"
        )

    with col2:
        median_km = int(df_train['km_driven'].median())
        st.metric(
            label="–ú–µ–¥–∏–∞–Ω–∞ –ø—Ä–æ–±–µ–≥–∞",
            value=f"{median_km} –∫–º"
        )

    with col3:
        median_mileage = df_train['mileage'].median()
        st.metric(
            label="–ú–µ–¥–∏–∞–Ω–∞ —Ä–∞—Å—Ö–æ–¥–∞ —Ç–æ–ø–ª–∏–≤–∞",
            value=f"{median_mileage}",

        )
    with col4:
        median_engine = int(df_train['engine'].median())
        st.metric(
            label="–ú–µ–¥–∏–∞–Ω–∞ –æ–±—ä–µ–º–∞ –¥–≤–∏–≥–∞—Ç–µ–ª—è",
            value=f"{median_engine}"
        )
    with col5:
        median_power = int(df_train['max_power'].median())
        st.metric(
            label="–ú–µ–¥–∏–∞–Ω–∞ –º–æ—â–Ω–æ—Å—Ç–∏",
            value=f"{median_power} –ª.—Å."
        )
    with col6:
        median_seats = int(df_train['seats'].median())
        st.metric(
            label="–ú–µ–¥–∏–∞–Ω–∞ –∫–æ–ª-–≤–∞ –º–µ—Å—Ç –≤ –º–∞—à–∏–Ω–µ",
            value=f"{median_seats}"
        )


median_metrics()

def visualize_train():
    df_train = load_train()

    fig = px.histogram(
        df_train,
        x='selling_price',
        nbins=50,
        title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω –Ω–∞ –º–∞—à–∏–Ω—ã'
    )
    st.plotly_chart(fig)

    #–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
    cor_matrix = df_train.select_dtypes(include=[np.number]).corr()
    corr_fig = px.imshow(
        cor_matrix,
        text_auto='.2f',
        color_continuous_scale='RdBu_r',
        title='–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É —á–∏—Å–ª–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –≤ train'
    )
    st.plotly_chart(corr_fig)
    #–°—Ç–æ–∏–º–æ—Å—Ç—å –º–∞—à–∏–Ω –æ—Ç –≤–∏–¥–∞ —Ç–æ–ø–ª–∏–≤–∞ –∏ –∫–æ—Ä–±–∫–∏ –ø–µ—Ä–µ–¥–∞—á
    fig_fuel=  px.bar(
        df_train,
        x='fuel',
        y='selling_price',
        color='transmission',
        title='–°—Ç–æ–∏–º–æ—Å—Ç—å –º–∞—à–∏–Ω –æ—Ç –≤–∏–¥–∞ —Ç–æ–ø–ª–∏–≤–∞ –∏ —Ç–∏–ø–∞ –∫–æ—Ä–æ–±–∫–∏',
        barmode='group'
    )
    st.plotly_chart(fig_fuel)

visualize_train()

st.subheader("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏")
#–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏
def visual_weights(model, feature_names):
    coefficients = model.coef_
    # –ò–¥–µ—é —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–∫–æ–≥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –∏–∑ –≤–µ—Å–æ–≤ –≤–∑—è–ª–∞ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö –Ω–∞ —Å—Ç–µ–ø–∏–∫–µ
    weights_df = pd.DataFrame({
        'feature': feature_names,
        'weight': coefficients,
        'abs_weight': np.abs(coefficients)
    }).sort_values('weight', ascending=False)

    #–¢–∞–±–ª–∏—Ü–∞ —Å –≤–µ—Å–∞–º–∏
    st.subheader("üìã –¢–∞–±–ª–∏—Ü–∞ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏")
    st.dataframe(
        weights_df[['feature', 'weight']].round(4),
        use_container_width=True
    )
    #–ì—Ä–∞—Ñ–∏–∫ –≤–µ—Å–æ–≤
    st.subheader("üìä –ì—Ä–∞—Ñ–∏–∫ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏")
    fig = px.bar(weights_df, 
                 x='weight', 
                 y='feature',
                 orientation='h',
                 color=weights_df['weight'] > 0,
                 color_discrete_map={True: 'royalblue', False: 'lightsteelblue'},
                 title='–ì—Ä–∞—Ñ–∏–∫ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏')

    st.plotly_chart(fig, use_container_width=True)

    return weights_df

visual_weights(model, feature_names)

st.subheader("üìà–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω –Ω–∞ –º–∞—à–∏–Ω—ã –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º –∏–∑ csv —Ñ–∞–π–ª–∞")

# –ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª", type=["csv"])

if uploaded_file is None:
    st.info("üëà –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
    st.stop()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
df = pd.read_csv(uploaded_file)


#–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —Ñ–∞–π–ª.
#1.–ù—É–∂–Ω–æ —É–±—Ä–∞—Ç—å –≤—Å–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏–∑ –∫–æ–ª–æ–Ω–æ–∫ –∏ —Å–¥–µ–ª–∞—Ç—å –∏—Ö —á–∏—Å–ª–æ–≤—ã–º–∏
#2.–ù—É–∂–Ω–æ —É–¥–∞–ª—Ç—å –≤—Å–µ –Ω–µ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, —Ç–∞–∫ –∫–∞–∫ –¥–µ–ª–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å
#3.–ù—É–∂–Ω–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –º–µ–¥–∏–Ω–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –º—ã —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏ –ø–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É, –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏
#4.–ù—É–∂–Ω–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ

def preprocess_data(df, medians, feature_names):

    processed_df = df.copy()
    
    #–£–±–∏—Ä–∞–µ–º ' kmpl' –∏–∑ mileage
    if 'mileage' in processed_df.columns:
        if processed_df['mileage'].dtype == 'object':
            processed_df['mileage'] = processed_df['mileage'].str.replace(' kmpl', '', regex=False)
        processed_df['mileage'] = pd.to_numeric(processed_df['mileage'], errors='coerce')
    
    #–£–±–∏—Ä–∞–µ–º ' CC' –∏–∑ engine
    if 'engine' in processed_df.columns:
        if processed_df['engine'].dtype == 'object':
            processed_df['engine'] = processed_df['engine'].str.replace(' CC', '', regex=False)
        processed_df['engine'] = pd.to_numeric(processed_df['engine'], errors='coerce')
    
    #–£–±–∏—Ä–∞–µ–º ' bhp' –¥–ª—è max_power
    if 'max_power' in processed_df.columns:
        if processed_df['max_power'].dtype == 'object':
            processed_df['max_power'] = processed_df['max_power'].str.replace(' bhp', '', regex=False)
        processed_df['max_power'] = pd.to_numeric(processed_df['max_power'], errors='coerce')
    
    #–£–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç—É –≤ pickle feature
    have_features = [col for col in feature_names if col in processed_df.columns]
    propush_features = [col for col in feature_names if col not in processed_df.columns]
    
    if propush_features:
        st.error(f"–í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {propush_features}")
        return None
    
    processed_df = processed_df[have_features]
    
    #–ó–∞–ø–æ–ª–Ω–∏–º –ø—Ä–æ–ø—É—Å–∫–∏ –º–µ–¥–∏–Ω–∞–º–∏ –∏–∑ pickle —Ñ–∞–π–ª–∞
    for feature in have_features:
        if processed_df[feature].isnull().any():
            processed_df[feature] = processed_df[feature].fillna(medians[feature])
    
    return processed_df
    
#–ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –∑–∞–≥—Ä—É–∑–∏–ª–æ—Å—å –∏–∑ csv
st.subheader("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
st.dataframe(df.head())
    
#–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏ —Å–¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
processed_features = preprocess_data(df, medians, feature_names)

st.header("–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –ª–∏–Ω–µ–π–Ω–æ–π –º–æ–¥–µ–ª–∏") 
st.subheader("–¢–æ–ª—å–∫–æ –Ω–∞ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö")    
st.caption("–õ–∏–Ω–µ–π–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–ª–æ—Ö–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–∏–ª—å–Ω–æ –æ—à–∏–±–∞–µ—Ç—Å—è")  

if processed_features is not None:
    #scaler –∑–∞–≥—Ä—É–∑–∏–ª–∏ –∏–∑ pickle, —Ç–∞–∫ –∫–∞–∫ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –º—ã –Ω–µ –º–æ–∂–µ–º –æ–±—É—á–∞—Ç—å, —Ç–æ–ª—å–∫–æ transform
    features_scaled = scaler.transform(processed_features)
    #–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    predictions = model.predict(features_scaled)
    #–°–¥–µ–ª–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–π —Ü–µ–Ω–æ–π
    result_df = processed_features.copy()
    result_df['predicted_price'] = predictions.round(2)
    
    #–í—ã–≤–µ–¥–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º —Ü–µ–Ω—ã
    st.dataframe(result_df, use_container_width=True)


  


